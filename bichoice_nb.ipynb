{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [open in Kaggle](https://www.kaggle.com/meishidou/notebookc618242876)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "\n",
    "# package in . directory\n",
    "from bichoice import utils\n",
    "from bichoice.data_processor import (\n",
    "    C3BinaryExample,\n",
    "    C3BinaryDataProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert transformers.__version__ == '4.1.1'\n",
    "\n",
    "# declare a namespace\n",
    "D = utils.GlobalSettings({\n",
    "        'DATADIR': './data/',\n",
    "        'MODELDIR': './outputs/bichoice_output/epoch-1/',\n",
    "    })\n",
    "\n",
    "# load training parameters\n",
    "argD = utils.GlobalSettings.from_json(\n",
    "    os.path.join(D.MODELDIR, 'global_settings.json'))\n",
    "print('this model is trained with following hyper parameters:')\n",
    "print(str(argD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select an Example for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_c3_example(e):\n",
    "    '''show all info of a single example in C3'''\n",
    "    print('-----PASSAGE-----')\n",
    "    print('\\n'.join(e.sentences))\n",
    "    print('-----QUESTION-----')\n",
    "    print(e.question)\n",
    "    print('-----OPTIONS-----')\n",
    "    for i, o in enumerate(e.options):\n",
    "        print('    {}: {}'.format(chr(i+ord('A')), o))\n",
    "    print('-----ANSWER-----')\n",
    "    l = e.label\n",
    "    print('    {}: {}'.format(chr(l+ord('A')), e.options[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = utils.get_all_C3examples(os.path.join(D.DATADIR, 'test.json'))\n",
    "test_e = random.choice(test)\n",
    "show_c3_example(test_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape C3 as Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C3Example_to_C3BinaryExample(eList):\n",
    "    '''\n",
    "    create `C3BinaryExample`s from `C3Example`s.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    `eList` : a list of `bichoice.utils.C3Example`\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    `out` : a list of `bichioce.data_processor.C3BinaryExample`.\n",
    "    '''\n",
    "    out = []\n",
    "    for e in eList:\n",
    "        passage = ''.join(e.sentences)\n",
    "        question = e.question\n",
    "        answer = e.options[e.label]\n",
    "        for o in e.options:\n",
    "            if o == answer:\n",
    "                continue\n",
    "            out.append(C3BinaryExample(passage, question, answer, o, 0))\n",
    "            out.append(C3BinaryExample(passage, question, o, answer, 1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_c3_binary_example(e):\n",
    "    '''show all info of a single `C3BinaryExample`'''\n",
    "    print('-----PASSAGE-----')\n",
    "    print(e.passage)\n",
    "    print('-----QUESTION-----')\n",
    "    print(e.question)\n",
    "    print('-----CHOICE_0-----')\n",
    "    print(e.choice_0)\n",
    "    print('-----CHOICE_1-----')\n",
    "    print(e.choice_1)\n",
    "    print('-----LABEL-----')\n",
    "    print(e.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposite this example to several binary examples\n",
    "test_b_e = C3Example_to_C3BinaryExample([test_e])\n",
    "for i, e in enumerate(test_b_e):\n",
    "    print('-----EXAMPLE{}-----'.format(i+1))\n",
    "    show_c3_binary_example(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer with Bi-Chioce Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and load state dict from a checkpoint \n",
    "D.DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(argD.MODEL_NAME)\n",
    "processor = C3BinaryDataProcessor(tokenizer, argD.MAX_LENGTH)\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(\n",
    "    argD.MODEL_NAME, num_labels=2)\n",
    "model.load_state_dict(torch.load(os.path.join(D.MODELDIR, 'model.bin')))\n",
    "model.to(D.DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(D, model, processor, passage, question, c1, c2, avg=True):\n",
    "    '''\n",
    "    compare two options and select one with the higher probability.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    `D` : instance of `GlobalSettings`\n",
    "    \n",
    "    `model` : binary classifier\n",
    "\n",
    "    `processor` : instance of `C3BinaryDataProcessor`\n",
    "\n",
    "    `passage` : str\n",
    "\n",
    "    `question` : str\n",
    "\n",
    "    `c1` : str\n",
    "\n",
    "    `c2` : str\n",
    "\n",
    "    `avg` : bool, if `True`, the we switch the position of `c1` and `c2` \n",
    "            and average output as probability. \n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    `label` : int, 0 means selecting c1, 1 means selecting c2\n",
    "    '''\n",
    "    # tokenizing\n",
    "    example1 = C3BinaryExample(passage, question, c1, c2)\n",
    "    example2 = C3BinaryExample(passage, question, c2, c1)\n",
    "    f1 = processor.convert_example_to_features(example1)\n",
    "    f2 = processor.convert_example_to_features(example2)\n",
    "    batch = {\n",
    "'input_ids': torch.LongTensor([f1.input_ids, f2.input_ids]),\n",
    "'attention_mask': torch.LongTensor([f1.input_mask,f2.input_mask]),\n",
    "'token_type_ids': torch.LongTensor([f1.segment_ids,f2.segment_ids]),\n",
    "    }\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(D.DEVICE)\n",
    "\n",
    "    model.to(D.DEVICE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(**batch)\n",
    "        logits = output.logits\n",
    "    if avg:\n",
    "        logit1 = (logits[0,0] + logits[1,1]).item()\n",
    "        logit2 = (logits[0,1] + logits[1,0]).item()\n",
    "    else:\n",
    "        logit1 = logits[0,0].item()\n",
    "        logit2 = logits[0,1].item()\n",
    "\n",
    "    return int(logit2 > logit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = test_e.options[0]\n",
    "# we sequentially compare all options\n",
    "for c2 in test_e.options[1:]:\n",
    "    print('we compare following options:')\n",
    "    print('    option1:', candidate)\n",
    "    print('    option2:', c2)\n",
    "    bin_label = compare(D, model, processor, ''.join(test_e.sentences), \n",
    "                        test_e.question, candidate, c2)\n",
    "    if bin_label == 1:\n",
    "        print('and we select:', c2)\n",
    "        candidate = c2\n",
    "    else:\n",
    "        print('and we select:', candidate)\n",
    "print('----------')\n",
    "print('infered answer:', candidate)\n",
    "print('correct answer:', test_e.options[test_e.label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
