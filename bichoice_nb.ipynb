{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "\n",
    "# package in . directory\n",
    "from bichoice import utils\n",
    "from bichoice.data_processor import (\n",
    "    C3BinaryExample,\n",
    "    C3BinaryDataProcessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this model is trained with following hyper parameters:\n",
      "{\n",
      "    \"MODEL_NAME\": \"bert-base-chinese\",\n",
      "    \"MAX_LENGTH\": 512,\n",
      "    \"BATCH_SIZE\": 4,\n",
      "    \"ACCUMULATION_STEPS\": 6,\n",
      "    \"LR\": 2e-05,\n",
      "    \"EPOCHS\": 8,\n",
      "    \"WARMUP_STEPS\": 500,\n",
      "    \"MAX_GRAD_NORM\": 1.0,\n",
      "    \"TRAIN_SET\": \"../outputs/csv-data/binary-train.csv\",\n",
      "    \"VALID_SET\": \"../outputs/csv-data/binary-dev.csv\",\n",
      "    \"VALID_SET_JSON\": \"../data/dev.json\",\n",
      "    \"TEST_SET_JSON\": \"../data/test.json\",\n",
      "    \"OUTDIR\": \"../outputs/bichoice_output/\",\n",
      "    \"FP16\": false,\n",
      "    \"DEVICE\": \"cuda:0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "assert transformers.__version__ == '4.1.1'\n",
    "\n",
    "# declare a namespace\n",
    "D = utils.GlobalSettings({\n",
    "        'DATADIR': './data/',\n",
    "        'MODELDIR': './outputs/bichoice_output/epoch-1/',\n",
    "    })\n",
    "\n",
    "# load training parameters\n",
    "argD = utils.GlobalSettings.from_json(\n",
    "    os.path.join(D.MODELDIR, 'global_settings.json'))\n",
    "print('this model is trained with following hyper parameters:')\n",
    "print(str(argD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select an Example for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_c3_example(e):\n",
    "    '''show all info of a single example in C3'''\n",
    "    print('-----PASSAGE-----')\n",
    "    print('\\n'.join(e.sentences))\n",
    "    print('-----QUESTION-----')\n",
    "    print(e.question)\n",
    "    print('-----OPTIONS-----')\n",
    "    for i, o in enumerate(e.options):\n",
    "        print('    {}: {}'.format(chr(i+ord('A')), o))\n",
    "    print('-----ANSWER-----')\n",
    "    l = e.label\n",
    "    print('    {}: {}'.format(chr(l+ord('A')), e.options[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----PASSAGE-----\n",
      "有一个博物馆被盗了，丢失了十件珍贵的文物，幸好一枚珍贵的钻石戒指没有被盗。警方经过多次努力也找不到线索，这时，一直很冷静的博物馆馆长提议让电视台采访他。不久，电视上播放了记者采访博物馆馆长的镜头。记者问：“这次共丢失了多少件文物?”馆长答：“十一件。”记者又问：“这些文物都很珍贵吗?”馆长答：“是的，都很珍贵，特别是一枚钻戒，价值连城。”时隔不久，警方就查到了线索，顺利地破了案。线索来源很简单，几个盗贼在互相殴打时被警方抓获，而他们殴斗的原因竟然是互相猜疑究竟是谁私藏了第十一件文物——那枚珍贵的钻戒。\n",
      "-----QUESTION-----\n",
      "博物馆被盗后，馆长做了什么?\n",
      "-----OPTIONS-----\n",
      "    A: 亲自去参加调查\n",
      "    B: 请记者来采访他\n",
      "    C: 转移走那枚钻戒\n",
      "    D: 看电视采访录像\n",
      "-----ANSWER-----\n",
      "    B: 请记者来采访他\n"
     ]
    }
   ],
   "source": [
    "test = utils.get_all_C3examples(os.path.join(D.DATADIR, 'test.json'))\n",
    "test_e = random.choice(test)\n",
    "show_c3_example(test_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape C3 as Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C3Example_to_C3BinaryExample(eList):\n",
    "    '''\n",
    "    create `C3BinaryExample`s from `C3Example`s.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    `eList` : a list of `bichoice.utils.C3Example`\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    `out` : a list of `bichioce.data_processor.C3BinaryExample`.\n",
    "    '''\n",
    "    out = []\n",
    "    for e in eList:\n",
    "        passage = ''.join(e.sentences)\n",
    "        question = e.question\n",
    "        answer = e.options[e.label]\n",
    "        for o in e.options:\n",
    "            if o == answer:\n",
    "                continue\n",
    "            out.append(C3BinaryExample(passage, question, answer, o, 0))\n",
    "            out.append(C3BinaryExample(passage, question, o, answer, 1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_c3_binary_example(e):\n",
    "    '''show all info of a single `C3BinaryExample`'''\n",
    "    print('-----PASSAGE-----')\n",
    "    print(e.passage)\n",
    "    print('-----QUESTION-----')\n",
    "    print(e.question)\n",
    "    print('-----CHOICE_0-----')\n",
    "    print(e.choice_0)\n",
    "    print('-----CHOICE_1-----')\n",
    "    print(e.choice_1)\n",
    "    print('-----LABEL-----')\n",
    "    print(e.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----EXAMPLE1-----\n",
      "-----PASSAGE-----\n",
      "有一个博物馆被盗了，丢失了十件珍贵的文物，幸好一枚珍贵的钻石戒指没有被盗。警方经过多次努力也找不到线索，这时，一直很冷静的博物馆馆长提议让电视台采访他。不久，电视上播放了记者采访博物馆馆长的镜头。记者问：“这次共丢失了多少件文物?”馆长答：“十一件。”记者又问：“这些文物都很珍贵吗?”馆长答：“是的，都很珍贵，特别是一枚钻戒，价值连城。”时隔不久，警方就查到了线索，顺利地破了案。线索来源很简单，几个盗贼在互相殴打时被警方抓获，而他们殴斗的原因竟然是互相猜疑究竟是谁私藏了第十一件文物——那枚珍贵的钻戒。\n",
      "-----QUESTION-----\n",
      "博物馆被盗后，馆长做了什么?\n",
      "-----CHOICE_0-----\n",
      "请记者来采访他\n",
      "-----CHOICE_1-----\n",
      "亲自去参加调查\n",
      "-----LABEL-----\n",
      "0\n",
      "-----EXAMPLE2-----\n",
      "-----PASSAGE-----\n",
      "有一个博物馆被盗了，丢失了十件珍贵的文物，幸好一枚珍贵的钻石戒指没有被盗。警方经过多次努力也找不到线索，这时，一直很冷静的博物馆馆长提议让电视台采访他。不久，电视上播放了记者采访博物馆馆长的镜头。记者问：“这次共丢失了多少件文物?”馆长答：“十一件。”记者又问：“这些文物都很珍贵吗?”馆长答：“是的，都很珍贵，特别是一枚钻戒，价值连城。”时隔不久，警方就查到了线索，顺利地破了案。线索来源很简单，几个盗贼在互相殴打时被警方抓获，而他们殴斗的原因竟然是互相猜疑究竟是谁私藏了第十一件文物——那枚珍贵的钻戒。\n",
      "-----QUESTION-----\n",
      "博物馆被盗后，馆长做了什么?\n",
      "-----CHOICE_0-----\n",
      "亲自去参加调查\n",
      "-----CHOICE_1-----\n",
      "请记者来采访他\n",
      "-----LABEL-----\n",
      "1\n",
      "-----EXAMPLE3-----\n",
      "-----PASSAGE-----\n",
      "有一个博物馆被盗了，丢失了十件珍贵的文物，幸好一枚珍贵的钻石戒指没有被盗。警方经过多次努力也找不到线索，这时，一直很冷静的博物馆馆长提议让电视台采访他。不久，电视上播放了记者采访博物馆馆长的镜头。记者问：“这次共丢失了多少件文物?”馆长答：“十一件。”记者又问：“这些文物都很珍贵吗?”馆长答：“是的，都很珍贵，特别是一枚钻戒，价值连城。”时隔不久，警方就查到了线索，顺利地破了案。线索来源很简单，几个盗贼在互相殴打时被警方抓获，而他们殴斗的原因竟然是互相猜疑究竟是谁私藏了第十一件文物——那枚珍贵的钻戒。\n",
      "-----QUESTION-----\n",
      "博物馆被盗后，馆长做了什么?\n",
      "-----CHOICE_0-----\n",
      "请记者来采访他\n",
      "-----CHOICE_1-----\n",
      "转移走那枚钻戒\n",
      "-----LABEL-----\n",
      "0\n",
      "-----EXAMPLE4-----\n",
      "-----PASSAGE-----\n",
      "有一个博物馆被盗了，丢失了十件珍贵的文物，幸好一枚珍贵的钻石戒指没有被盗。警方经过多次努力也找不到线索，这时，一直很冷静的博物馆馆长提议让电视台采访他。不久，电视上播放了记者采访博物馆馆长的镜头。记者问：“这次共丢失了多少件文物?”馆长答：“十一件。”记者又问：“这些文物都很珍贵吗?”馆长答：“是的，都很珍贵，特别是一枚钻戒，价值连城。”时隔不久，警方就查到了线索，顺利地破了案。线索来源很简单，几个盗贼在互相殴打时被警方抓获，而他们殴斗的原因竟然是互相猜疑究竟是谁私藏了第十一件文物——那枚珍贵的钻戒。\n",
      "-----QUESTION-----\n",
      "博物馆被盗后，馆长做了什么?\n",
      "-----CHOICE_0-----\n",
      "转移走那枚钻戒\n",
      "-----CHOICE_1-----\n",
      "请记者来采访他\n",
      "-----LABEL-----\n",
      "1\n",
      "-----EXAMPLE5-----\n",
      "-----PASSAGE-----\n",
      "有一个博物馆被盗了，丢失了十件珍贵的文物，幸好一枚珍贵的钻石戒指没有被盗。警方经过多次努力也找不到线索，这时，一直很冷静的博物馆馆长提议让电视台采访他。不久，电视上播放了记者采访博物馆馆长的镜头。记者问：“这次共丢失了多少件文物?”馆长答：“十一件。”记者又问：“这些文物都很珍贵吗?”馆长答：“是的，都很珍贵，特别是一枚钻戒，价值连城。”时隔不久，警方就查到了线索，顺利地破了案。线索来源很简单，几个盗贼在互相殴打时被警方抓获，而他们殴斗的原因竟然是互相猜疑究竟是谁私藏了第十一件文物——那枚珍贵的钻戒。\n",
      "-----QUESTION-----\n",
      "博物馆被盗后，馆长做了什么?\n",
      "-----CHOICE_0-----\n",
      "请记者来采访他\n",
      "-----CHOICE_1-----\n",
      "看电视采访录像\n",
      "-----LABEL-----\n",
      "0\n",
      "-----EXAMPLE6-----\n",
      "-----PASSAGE-----\n",
      "有一个博物馆被盗了，丢失了十件珍贵的文物，幸好一枚珍贵的钻石戒指没有被盗。警方经过多次努力也找不到线索，这时，一直很冷静的博物馆馆长提议让电视台采访他。不久，电视上播放了记者采访博物馆馆长的镜头。记者问：“这次共丢失了多少件文物?”馆长答：“十一件。”记者又问：“这些文物都很珍贵吗?”馆长答：“是的，都很珍贵，特别是一枚钻戒，价值连城。”时隔不久，警方就查到了线索，顺利地破了案。线索来源很简单，几个盗贼在互相殴打时被警方抓获，而他们殴斗的原因竟然是互相猜疑究竟是谁私藏了第十一件文物——那枚珍贵的钻戒。\n",
      "-----QUESTION-----\n",
      "博物馆被盗后，馆长做了什么?\n",
      "-----CHOICE_0-----\n",
      "看电视采访录像\n",
      "-----CHOICE_1-----\n",
      "请记者来采访他\n",
      "-----LABEL-----\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# decomposite this example to several binary examples\n",
    "test_b_e = C3Example_to_C3BinaryExample([test_e])\n",
    "for i, e in enumerate(test_b_e):\n",
    "    print('-----EXAMPLE{}-----'.format(i+1))\n",
    "    show_c3_binary_example(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer with Bi-Chioce Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d2ceb7a35a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model = transformers.BertForSequenceClassification.from_pretrained(\n\u001b[1;32m      6\u001b[0m     argD.MODEL_NAME, num_labels=2)\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODELDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    136\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# initialize model and load state dict from a checkpoint \n",
    "D.DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(argD.MODEL_NAME)\n",
    "processor = C3BinaryDataProcessor(tokenizer, argD.MAX_LENGTH)\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(\n",
    "    argD.MODEL_NAME, num_labels=2)\n",
    "model.load_state_dict(torch.load(os.path.join(D.MODELDIR, 'model.bin')))\n",
    "model.to(D.DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(D, model, processor, passage, question, c1, c2, avg=True):\n",
    "    '''\n",
    "    compare two options and select one with the higher probability.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    `D` : instance of `GlobalSettings`\n",
    "    \n",
    "    `model` : binary classifier\n",
    "\n",
    "    `processor` : instance of `C3BinaryDataProcessor`\n",
    "\n",
    "    `passage` : str\n",
    "\n",
    "    `question` : str\n",
    "\n",
    "    `c1` : str\n",
    "\n",
    "    `c2` : str\n",
    "\n",
    "    `avg` : bool, if `True`, the we switch the position of `c1` and `c2` \n",
    "            and average output as probability. \n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    `label` : int, 0 means selecting c1, 1 means selecting c2\n",
    "    '''\n",
    "    # tokenizing\n",
    "    example1 = C3BinaryExample(passage, question, c1, c2)\n",
    "    example2 = C3BinaryExample(passage, question, c2, c1)\n",
    "    f1 = processor.convert_example_to_features(example1)\n",
    "    f2 = processor.convert_example_to_features(example2)\n",
    "    batch = {\n",
    "'input_ids': torch.LongTensor([f1.input_ids, f2.input_ids]),\n",
    "'attention_mask': torch.LongTensor([f1.input_mask,f2.input_mask]),\n",
    "'token_type_ids': torch.LongTensor([f1.segment_ids,f2.segment_ids]),\n",
    "    }\n",
    "    for k in batch:\n",
    "        batch[k] = batch[k].to(D.DEVICE)\n",
    "\n",
    "    model.to(D.DEVICE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(**batch)\n",
    "        logits = output.logits\n",
    "    if avg:\n",
    "        logit1 = (logits[0,0] + logits[1,1]).item()\n",
    "        logit2 = (logits[0,1] + logits[1,0]).item()\n",
    "    else:\n",
    "        logit1 = logits[0,0].item()\n",
    "        logit2 = logits[0,1].item()\n",
    "\n",
    "    return int(logit2 > logit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = test_e.options[0]\n",
    "# we sequentially compare all options\n",
    "for c2 in test_e.options[1:]:\n",
    "    print('we compare following options:')\n",
    "    print('    option1:', candidate)\n",
    "    print('    option2:', c2)\n",
    "    bin_label = compare(D, model, processor, ''.join(test_e.sentences), \n",
    "                        test_e.question, candidate, c2)\n",
    "    if bin_label == 1:\n",
    "        print('and we select:', c2)\n",
    "        candidate = c2\n",
    "    else:\n",
    "        print('and we select:', candidate)\n",
    "print('----------')\n",
    "print('infered answer:', candidate)\n",
    "print('correct answer:', test_e.options[test_e.label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
